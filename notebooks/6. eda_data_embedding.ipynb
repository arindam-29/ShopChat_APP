{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Full Name: \n",
    "    \n",
    "`Arindam Choudhury`\n",
    "\n",
    "    Nutan Mandale\n",
    "    \n",
    "    Humberto Gonzalez Granda\n",
    "\n",
    "Your Uplevel Email Address:\n",
    "    \n",
    "    arindam.choudhury.email@gmail.com\n",
    "    \n",
    "    nutan.mandale@gmail.com\n",
    "    \n",
    "    HumbertoGonzalezGranda@gmail.com\n",
    "\n",
    "Name of the Problem Statement of Submission:\n",
    "    \n",
    "    ShopTalk (Project-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arindam/Machine Learning/GitHub_Repository/ShopChat_APP/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "from src.utils import upload_directory_to_s3\n",
    "from dataclasses import dataclass,field\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataEmbeddingConfig:\n",
    "    model: str = None\n",
    "    \n",
    "    load_dotenv()\n",
    "    genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "    os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    ABO_BUCKET_NAME:        str = os.getenv(\"ABO_BUCKET_NAME\")\n",
    "    YOUR_S3_BUCKET_NAME:    str = os.getenv(\"YOUR_S3_BUCKET_NAME\")\n",
    "    ARTIFACTS_FOLDER:       str = os.getenv(\"ARTIFACTS_FOLDER\")\n",
    "    WORKING_DIR:            str = os.getenv(\"WORKING_DIR\")\n",
    "    EDA_FOLDER_NAME:        str = os.getenv(\"EDA_FOLDER_NAME\")\n",
    "\n",
    "    json_file_s3:     str = f\"s3://{YOUR_S3_BUCKET_NAME}/{EDA_FOLDER_NAME}/dataset.json\" # Used EDA file for embedding\n",
    "    json_file_local:  str = f\"{WORKING_DIR}/dataset_copy.json\"\n",
    "\n",
    "    vector_db_s3: str = field(init=False)\n",
    "    embeddings: object  = field(init=False)\n",
    "    \n",
    "    if not os.path.exists(WORKING_DIR):\n",
    "        os.makedirs(WORKING_DIR)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.model == \"google\":\n",
    "            logging.info(\"Data Embedding - Embedding Model selected is Google.\")\n",
    "            self.vector_db_s3: str = \"GOOGLE_FAISS_DB\"\n",
    "            self.vector_db_local: str = f\"{self.WORKING_DIR}GOOGLE_FAISS_DB\"\n",
    "            self.embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\")         \n",
    "        elif self.model == \"openai\":\n",
    "            logging.info(\"Data Embedding - Embedding Model selected is OpenAI.\")\n",
    "            self.vector_db_s3: str = \"OPENAI_FAISS_DB\"\n",
    "            self.vector_db_local: str = f\"{self.WORKING_DIR}OPENAI_FAISS_DB\"\n",
    "            self.embeddings = OpenAIEmbeddings()\n",
    "        elif self.model == \"finetune\":\n",
    "            logging.info(\"Data Embedding - Embedding Model selected is HuggingFace Finetune model.\")\n",
    "            self.vector_db_s3: str = \"FINETUNE_FAISS_DB\"\n",
    "            self.vector_db_local: str = f\"{self.WORKING_DIR}FINETUNE_FAISS_DB\"\n",
    "            FINETUNE_MODEL_PATH: str = f\"s3://{self.YOUR_S3_BUCKET_NAME}/FINETUNE/finetuned_model\"\n",
    "            self.embeddings = HuggingFaceEmbeddings(model_name = FINETUNE_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEmbedding:\n",
    "    def __init__(self, model):\n",
    "        self.ingestion_config=DataEmbeddingConfig(model)\n",
    "    \n",
    "    def initiate_data_embedding(self):\n",
    "        logging.info(\"Data Embedding - started\")\n",
    "        try:\n",
    "            file_path = self.ingestion_config.json_file_s3\n",
    "            dataset = pd.read_json(file_path)\n",
    "            dataset.to_json(self.ingestion_config.json_file_local, orient='records')\n",
    "            logging.info(\"Data Embedding - Json file loaded from AWS S3 to dataframe\")\n",
    "\n",
    "            loader = JSONLoader(file_path=self.ingestion_config.json_file_local, jq_schema=\".[]\", text_content=False)\n",
    "            documents = loader.load()\n",
    "            vectors_db = FAISS.from_documents(documents, self.ingestion_config.embeddings)\n",
    "            logging.info(\"Data Embedding - FIASS DB created successfully\")\n",
    "\n",
    "            vectors_db.save_local(self.ingestion_config.vector_db_local)\n",
    "            logging.info(\"Data Embedding - FIASS DB Loading to AWS S3 started\")\n",
    "            upload_directory_to_s3(self.ingestion_config.YOUR_S3_BUCKET_NAME, self.ingestion_config.vector_db_s3, self.ingestion_config.vector_db_local)\n",
    "\n",
    "            if os.path.exists(self.ingestion_config.WORKING_DIR):\n",
    "                shutil.rmtree(self.ingestion_config.WORKING_DIR)\n",
    "                print(f\"{self.ingestion_config.WORKING_DIR} folder removed successfully.\")   \n",
    "\n",
    "            logging.info(\"Data Embedding - completed\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded GOOGLE_FAISS_DB/index.faiss to S3 bucket shopchat-s3-buckect\n",
      "Uploaded GOOGLE_FAISS_DB/index.pkl to S3 bucket shopchat-s3-buckect\n",
      "Download folder removed successfully.\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    model = \"google\"\n",
    "    #model = \"openai\"\n",
    "    #model = \"finetune\"\n",
    "    obj=DataEmbedding(model)\n",
    "    data = obj.initiate_data_embedding()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
